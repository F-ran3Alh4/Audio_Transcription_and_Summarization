{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Hugging Face Text-to-Text Pipeline**\n",
        "##**Overview**\n",
        "\n",
        "This project demonstrates how to use the Hugging Face text-to-text pipeline without the need for a Gradio interface. The project utilizes the Whisper model from OpenAI to convert audio files to text and the \"google/pegasus-large\" model from Hugging Face to summarize the extracted text from the audio."
      ],
      "metadata": {
        "id": "Jn1kqiWyllJR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DqyXTE095ysy",
        "outputId": "54bdfc46-edc0-4a07-a066-5963db429861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20231117)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.4.0+cu121)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.3.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.7.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Install Hugging Face Transformers and OpenAI Whisper libraries\n",
        "!pip install transformers openai-whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Code explain**\n",
        "**ʘ** **Import Libraries**:\n",
        "  - **Whisper Library**: Used to convert audio files into text.\n",
        "  - **Transformers Library**: Provides tools for running summarization models.\n",
        "\n",
        "\n",
        "**ʘ** **Load Models**:\n",
        "  - **Whisper Model**: Converts audio into text.\n",
        "  - **Summarization Model**: Uses \"google/pegasus-large\" to summarize the text.\n",
        "\n",
        "\n",
        "**ʘ** **Functions**:\n",
        "  - **audio_to_text(audio_file)**:\n",
        "    - Converts the audio file at `audio_file` path into text.\n",
        "    - Returns the text extracted from the audio.\n",
        "  - **summarize_text(text)**:\n",
        "    - Summarizes the `text` with a summary length between 30 and 130 words.\n",
        "    - Returns the summarized text.\n",
        "\n",
        "\n",
        "**ʘ** **Process**:\n",
        "  1. **Specify the Path**: Set the path to your audio file.\n",
        "  2. **Convert Audio to Text**: Use `audio_to_text` to get the text from the audio file.\n",
        "  3. **Summarize the Text**: Use `summarize_text` to get a summary of the extracted text.\n",
        "  4. **Print Results**:\n",
        "     - Print the transcribed text.\n",
        "     - Print the summarized text."
      ],
      "metadata": {
        "id": "uVvy2xE6AQML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Whisper library for speech-to-text conversion\n",
        "import whisper\n",
        "\n",
        "# Import the pipeline function from the Transformers library to use summarization models\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the base Whisper model for converting audio to text\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Initialize a pipeline for text summarization using the \"google/pegasus-large\" model from Hugging Face\n",
        "summarization = pipeline(\"summarization\", model=\"google/pegasus-large\")\n",
        "\n",
        "# Function to convert audio to text using the Whisper model\n",
        "def audio_to_text(audio_file):\n",
        "    # Transcribe the audio file to text using the Whisper model\n",
        "    result = model.transcribe(audio_file)\n",
        "    # Return the extracted text from the audio file\n",
        "    return result['text']\n",
        "\n",
        "# Function to summarize the text using the chosen summarization model\n",
        "def summarize_text(text):\n",
        "    # Summarize the text using the summarization model, setting the summary length between 30 and 130 words\n",
        "    return summarization(text, min_length=30, max_length=130)[0]['summary_text']\n",
        "\n",
        "# Specify the path of the audio file to be processed\n",
        "audio_file = \"/content/audio-editor-output.mp3\"\n",
        "\n",
        "# Convert the audio file to text\n",
        "text = audio_to_text(audio_file)\n",
        "\n",
        "# Summarize the extracted text from the audio\n",
        "summary = summarize_text(text)\n",
        "\n",
        "# Print the transcribed text from the audio\n",
        "print(\"Transcript:\", text)\n",
        "\n",
        "# Print the summary of the text\n",
        "print(\"Summary:\", summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebebRBbgER_H",
        "outputId": "86f4a5f9-4be1-4d5a-da64-ea623e60fb53",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript:  Recorded books is pleased to present the Modern Scholar series, where great professors teach you. My name is Richard Davidson, and I'll be your host. Today, we begin a course entitled, Discovering the Philosopher in You, The Big Questions in Philosophy. Your professor is Colin McGinn of Rutgers University. Professor McGinn was educated at Oxford University and has written extensively on philosophy in publications such as The New York Review of Books, The London Review of Books, The New Republic, and The New York Times Book Review. He's written fourteen books, among them the highly praised title, The Making of a Philosopher. As well as works entitled, The Mysterious Flame, The Character of Mind, and Ethics, Evil, and Fiction. Of all the branches of intellectual inquiry, philosophy seems to be the most essence.\n",
            "Summary: Professor McGinn was educated at Oxford University and has written extensively on philosophy in publications such as The New York Review of Books, The London Review of Books, The New Republic, and The New York Times Book Review.\n"
          ]
        }
      ]
    }
  ]
}